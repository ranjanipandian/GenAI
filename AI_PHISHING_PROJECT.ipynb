{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJgwU8Tey3iSCJ2N9OF89G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranjanipandian/GenAI/blob/main/AI_PHISHING_PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZePgSSpmNEJ",
        "outputId": "8cfe3977-3435-4884-a726-7ee7c5d131d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tld in /usr/local/lib/python3.10/dist-packages (0.13)\n"
          ]
        }
      ],
      "source": [
        "pip install tld"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "import socket"
      ],
      "metadata": {
        "id": "qvJlxZuOn1Tc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-whois"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRa0uSvNoYB8",
        "outputId": "5f514692-1583-4b79-f8ea-7ba2fb7572bb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-whois\n",
            "  Downloading python_whois-0.9.2-py3-none-any.whl (103 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/103.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m102.4/103.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-whois\n",
            "Successfully installed python-whois-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whois\n",
        "import socket"
      ],
      "metadata": {
        "id": "ifBnUgi6omh1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import urlparse\n",
        "from tld import get_tld\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "t3m65N4gonaF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class urlfetcher:\n",
        "    def __init__(self,url):\n",
        "        self.url=url\n",
        "def get_details_from_url(url):\n",
        "    try:\n",
        "        # Send a GET request to the URL\n",
        "        response = requests.get(url)\n",
        "\n",
        "        # Check if the request was successful (status code 200)\n",
        "        if response.status_code == 200:\n",
        "            # Parse the HTML content using BeautifulSoup\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            # Extracting URL details\n",
        "            url_length = len(url)\n",
        "            parsed_url = urlparse(url)\n",
        "            hostname = parsed_url.netloc\n",
        "            hostname_length = len(hostname)\n",
        "            ip = socket.gethostbyname(hostname)\n",
        "\n",
        "            # Counting occurrences of specific characters in URL\n",
        "            nb_dots = 1 if '.' in hostname else 0\n",
        "            nb_hyphens = 1 if '-' in hostname else 0\n",
        "            nb_at = 1 if '@' in hostname else 0\n",
        "            nb_qm = 1 if '?' in hostname else 0\n",
        "            nb_and =1 if '&' in hostname else 0\n",
        "            nb_or =1 if '|' in hostname else 0\n",
        "            nb_eq = 1 if '=' in hostname else 0\n",
        "            nb_underscore = 1 if '_' in hostname else 0\n",
        "            nb_tilde = 1 if '~' in hostname else 0\n",
        "            nb_percent = 1 if '%' in hostname else 0\n",
        "            nb_slash = 1 if '/' in hostname else 0\n",
        "            nb_star = 1 if '*' in hostname else 0\n",
        "            nb_colon = 1 if ':' in hostname else 0\n",
        "            nb_comma = 1 if ',' in hostname else 0\n",
        "            nb_semicolon =1 if ';' in hostname else 0\n",
        "            nb_dollar = 1 if '$' in hostname else 0\n",
        "            nb_space = 1 if ' ' in hostname else 0\n",
        "            nb_www = 1 if 'www' in hostname else 0\n",
        "            nb_com = 1 if '.com' in hostname else 0\n",
        "            nb_dslash = 1 if '//' in hostname else 0\n",
        "\n",
        "            # Check if URL uses http or https\n",
        "            http_in_path = 1 if 'http://' in url else 0\n",
        "            https_token = 1 if 'https' in url else 0\n",
        "\n",
        "            # Ratios of digits in URL and hostname\n",
        "            ratio_digits_url = sum(1 for c in url if c.isdigit()) / len(url)\n",
        "            ratio_digits_host = sum(1 for c in hostname if c.isdigit()) / len(hostname)\n",
        "\n",
        "            # Extracting domain details\n",
        "            tld_in_path = 1 if get_tld(url, fail_silently=True) in parsed_url.path else 0\n",
        "            tld_in_subdomain = 1 if get_tld(url, fail_silently=True) in hostname.split('.')[:-1] else 0\n",
        "            abnormal_subdomain = 1 if re.match(r\"^(www|mail|webmail|email)\\.\", hostname) else 0\n",
        "            nb_subdomains = len(hostname.split('.')) - 1\n",
        "            prefix_suffix = 1 if '-' in parsed_url.netloc else 0\n",
        "            random_domain = 1 if re.search(r\"[0-9]{4,}\", hostname) else 0\n",
        "            shortening_service = 1 if 'bit.ly' in hostname or 'tinyurl' in hostname else 0\n",
        "\n",
        "            # Path details\n",
        "            path_extension = parsed_url.path.split('.')[-1]\n",
        "            nb_redirection = len(soup.find_all('meta', attrs={'http-equiv': 'refresh'}))\n",
        "            nb_external_redirection = len([link for link in soup.find_all('a') if 'http' in link.get('href', '')])\n",
        "\n",
        "            # ... Continue fetching other details as required ...\n",
        "\n",
        "            return {\n",
        "                # Add all the extracted details here as key-value pairs\n",
        "                'url_length': url_length,\n",
        "                'length_hostname': hostname_length,\n",
        "                'ip': ip,\n",
        "                'nb_dots': nb_dots,\n",
        "                'nb_hyphens': nb_hyphens,\n",
        "                'nb_at': nb_at,\n",
        "                'nb_qm': nb_qm,\n",
        "                'nb_and': nb_and,\n",
        "                'nb_or': nb_or,\n",
        "                'nb_eq': nb_eq,\n",
        "                'nb_underscore': nb_underscore,\n",
        "                'nb_tilde': nb_tilde,\n",
        "                'nb_percent': nb_percent,\n",
        "                'nb_slash': nb_slash,\n",
        "                'nb_star': nb_star,\n",
        "                'nb_colon': nb_colon,\n",
        "                'nb_comma': nb_comma,\n",
        "                'nb_semicolon': nb_semicolon,\n",
        "                'nb_dollar': nb_dollar,\n",
        "                'nb_space': nb_space,\n",
        "                'nb_www': nb_www,\n",
        "                'nb_com': nb_com,\n",
        "                'nb_dslash': nb_dslash,\n",
        "                'http_in_path': http_in_path,\n",
        "                'https_token': https_token,\n",
        "                'ratio_digits_url': ratio_digits_url,\n",
        "                'ratio_digits_host': ratio_digits_host,\n",
        "                'tld_in_path': tld_in_path,\n",
        "                'tld_in_subdomain': tld_in_subdomain,\n",
        "                'abnormal_subdomain': abnormal_subdomain,\n",
        "                'nb_subdomains': nb_subdomains,\n",
        "                'prefix_suffix': prefix_suffix,\n",
        "                'random_domain': random_domain,\n",
        "                'shortening_service': shortening_service,\n",
        "                'path_extension': path_extension,\n",
        "                'nb_redirection': nb_redirection,\n",
        "                'nb_external_redirection': nb_external_redirection,\n",
        "                # ... Continue adding other details ...\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            print(f\"Failed to fetch data from the URL. Status code: {response.status_code}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n"
      ],
      "metadata": {
        "id": "l3MKx2grores"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'your_url_here' with the actual URL you want to fetch data from\n",
        "url = input()\n",
        "details = get_details_from_url(url)\n",
        "\n",
        "if details:\n",
        "    # Print all the fetched details here\n",
        "    print(details)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYrvtJFHo6nq",
        "outputId": "f1e8ffdd-0307-4a43-b0fa-bc51e045bb91"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://colab.research.google.com/drive/19SUA94CKeGLfdaUOLo0lnq-pLu4EsqGI#scrollTo=TYrvtJFHo6nq\n",
            "{'url_length': 95, 'length_hostname': 25, 'ip': '216.239.34.180', 'nb_dots': 1, 'nb_hyphens': 0, 'nb_at': 0, 'nb_qm': 0, 'nb_and': 0, 'nb_or': 0, 'nb_eq': 0, 'nb_underscore': 0, 'nb_tilde': 0, 'nb_percent': 0, 'nb_slash': 0, 'nb_star': 0, 'nb_colon': 0, 'nb_comma': 0, 'nb_semicolon': 0, 'nb_dollar': 0, 'nb_space': 0, 'nb_www': 0, 'nb_com': 1, 'nb_dslash': 0, 'http_in_path': 0, 'https_token': 1, 'ratio_digits_url': 0.07368421052631578, 'ratio_digits_host': 0.0, 'tld_in_path': 0, 'tld_in_subdomain': 0, 'abnormal_subdomain': 0, 'nb_subdomains': 3, 'prefix_suffix': 0, 'random_domain': 0, 'shortening_service': 0, 'path_extension': '/drive/19SUA94CKeGLfdaUOLo0lnq-pLu4EsqGI', 'nb_redirection': 0, 'nb_external_redirection': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "7cWrhxTCqI3n"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "XpY_QN2rqM0U"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('dataset.csv')\n",
        "X=df.drop(columns='status')\n",
        "Y=df['status']\n",
        "X_train,Y_train,X_test,Y_test=train_test_split(test_size=0.3,random_state=40)"
      ],
      "metadata": {
        "id": "BjH-R_JTqPlD"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}